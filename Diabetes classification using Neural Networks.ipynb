{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "46eb5e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526360f0",
   "metadata": {},
   "source": [
    "### keras documentation: https://keras.io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdef666",
   "metadata": {},
   "source": [
    "## Loading Diabetes Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b00e4d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loda the dataset for\n",
    "data = pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc801b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI   \n",
       "0            6      148             72             35        0  33.6  \\\n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44eed242",
   "metadata": {},
   "source": [
    "### Goal: to predict based on diagnostic measurements whether a patient has diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8b07ff2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Outcome'>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "data['Outcome'].value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f3db63",
   "metadata": {},
   "source": [
    "### Preparing Data for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "216cc214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into input (X) and output (y) variables\n",
    "predictors = data.iloc[:,0:8]\n",
    "response = data.iloc[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "55b043d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 8) (614,)\n",
      "(154, 8) (154,)\n"
     ]
    }
   ],
   "source": [
    "# create training and testing vars\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors, response, test_size=0.2)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b1f7d4",
   "metadata": {},
   "source": [
    "### Training Neural Network model\n",
    "\n",
    "- **There are Two ways to build Keras model:**\n",
    "    - **Sequential**\n",
    "        - **Sequential API allows you to create models layer-by-layer**\n",
    "    - **Functional**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "965e1ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the keras model - layer by layer\n",
    "kerasmodel = Sequential() # initializing model - Dense for fully connected layer\n",
    "kerasmodel.add(Dense(12, input_dim=8, activation='relu')) # First Hidden layer\n",
    "kerasmodel.add(Dense(8, activation='relu')) # Relu to avoid vanishing/exploding gradient problem - #\n",
    "kerasmodel.add(Dense(1, activation='sigmoid')) # since output is binary so \"sigmoid\" - # Outputlayer\n",
    "\n",
    "# Weight and bias initialization are done by keras default methods using \"'glorot_uniform'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3f3a46dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling model\n",
    "kerasmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f9f01214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "62/62 [==============================] - 0s 464us/step - loss: 6.7235 - accuracy: 0.6580\n",
      "Epoch 2/150\n",
      "62/62 [==============================] - 0s 454us/step - loss: 1.5601 - accuracy: 0.6629\n",
      "Epoch 3/150\n",
      "62/62 [==============================] - 0s 552us/step - loss: 0.9368 - accuracy: 0.6466\n",
      "Epoch 4/150\n",
      "62/62 [==============================] - 0s 394us/step - loss: 0.7675 - accuracy: 0.6547\n",
      "Epoch 5/150\n",
      "62/62 [==============================] - 0s 399us/step - loss: 0.7243 - accuracy: 0.6580\n",
      "Epoch 6/150\n",
      "62/62 [==============================] - 0s 428us/step - loss: 0.7031 - accuracy: 0.6580\n",
      "Epoch 7/150\n",
      "62/62 [==============================] - 0s 408us/step - loss: 0.6670 - accuracy: 0.6694\n",
      "Epoch 8/150\n",
      "62/62 [==============================] - 0s 410us/step - loss: 0.6841 - accuracy: 0.6678\n",
      "Epoch 9/150\n",
      "62/62 [==============================] - 0s 419us/step - loss: 0.6781 - accuracy: 0.6498\n",
      "Epoch 10/150\n",
      "62/62 [==============================] - 0s 429us/step - loss: 0.6457 - accuracy: 0.6596\n",
      "Epoch 11/150\n",
      "62/62 [==============================] - 0s 413us/step - loss: 0.6330 - accuracy: 0.6694\n",
      "Epoch 12/150\n",
      "62/62 [==============================] - 0s 443us/step - loss: 0.6294 - accuracy: 0.6678\n",
      "Epoch 13/150\n",
      "62/62 [==============================] - 0s 425us/step - loss: 0.6270 - accuracy: 0.6726\n",
      "Epoch 14/150\n",
      "62/62 [==============================] - 0s 432us/step - loss: 0.6271 - accuracy: 0.6547\n",
      "Epoch 15/150\n",
      "62/62 [==============================] - 0s 409us/step - loss: 0.5993 - accuracy: 0.6726\n",
      "Epoch 16/150\n",
      "62/62 [==============================] - 0s 412us/step - loss: 0.5971 - accuracy: 0.6743\n",
      "Epoch 17/150\n",
      "62/62 [==============================] - 0s 439us/step - loss: 0.5916 - accuracy: 0.6840\n",
      "Epoch 18/150\n",
      "62/62 [==============================] - 0s 460us/step - loss: 0.5860 - accuracy: 0.6922\n",
      "Epoch 19/150\n",
      "62/62 [==============================] - 0s 414us/step - loss: 0.6096 - accuracy: 0.6808\n",
      "Epoch 20/150\n",
      "62/62 [==============================] - 0s 445us/step - loss: 0.5883 - accuracy: 0.6792\n",
      "Epoch 21/150\n",
      "62/62 [==============================] - 0s 432us/step - loss: 0.5890 - accuracy: 0.6987\n",
      "Epoch 22/150\n",
      "62/62 [==============================] - 0s 433us/step - loss: 0.5811 - accuracy: 0.6824\n",
      "Epoch 23/150\n",
      "62/62 [==============================] - 0s 408us/step - loss: 0.5747 - accuracy: 0.6824\n",
      "Epoch 24/150\n",
      "62/62 [==============================] - 0s 422us/step - loss: 0.5550 - accuracy: 0.7036\n",
      "Epoch 25/150\n",
      "62/62 [==============================] - 0s 419us/step - loss: 0.5582 - accuracy: 0.7020\n",
      "Epoch 26/150\n",
      "62/62 [==============================] - 0s 420us/step - loss: 0.5583 - accuracy: 0.6938\n",
      "Epoch 27/150\n",
      "62/62 [==============================] - 0s 419us/step - loss: 0.5444 - accuracy: 0.7085\n",
      "Epoch 28/150\n",
      "62/62 [==============================] - 0s 428us/step - loss: 0.5543 - accuracy: 0.7068\n",
      "Epoch 29/150\n",
      "62/62 [==============================] - 0s 439us/step - loss: 0.5528 - accuracy: 0.6987\n",
      "Epoch 30/150\n",
      "62/62 [==============================] - 0s 419us/step - loss: 0.5720 - accuracy: 0.6889\n",
      "Epoch 31/150\n",
      "62/62 [==============================] - 0s 400us/step - loss: 0.5508 - accuracy: 0.6987\n",
      "Epoch 32/150\n",
      "62/62 [==============================] - 0s 433us/step - loss: 0.5494 - accuracy: 0.7101\n",
      "Epoch 33/150\n",
      "62/62 [==============================] - 0s 430us/step - loss: 0.5567 - accuracy: 0.6954\n",
      "Epoch 34/150\n",
      "62/62 [==============================] - 0s 380us/step - loss: 0.5511 - accuracy: 0.7052\n",
      "Epoch 35/150\n",
      "62/62 [==============================] - 0s 451us/step - loss: 0.5513 - accuracy: 0.7052\n",
      "Epoch 36/150\n",
      "62/62 [==============================] - 0s 450us/step - loss: 0.5494 - accuracy: 0.7003\n",
      "Epoch 37/150\n",
      "62/62 [==============================] - 0s 432us/step - loss: 0.5373 - accuracy: 0.7117\n",
      "Epoch 38/150\n",
      "62/62 [==============================] - 0s 424us/step - loss: 0.5316 - accuracy: 0.7248\n",
      "Epoch 39/150\n",
      "62/62 [==============================] - 0s 419us/step - loss: 0.5391 - accuracy: 0.7150\n",
      "Epoch 40/150\n",
      "62/62 [==============================] - 0s 421us/step - loss: 0.5441 - accuracy: 0.7199\n",
      "Epoch 41/150\n",
      "62/62 [==============================] - 0s 423us/step - loss: 0.5364 - accuracy: 0.7166\n",
      "Epoch 42/150\n",
      "62/62 [==============================] - 0s 426us/step - loss: 0.5335 - accuracy: 0.7117\n",
      "Epoch 43/150\n",
      "62/62 [==============================] - 0s 422us/step - loss: 0.5281 - accuracy: 0.7199\n",
      "Epoch 44/150\n",
      "62/62 [==============================] - 0s 428us/step - loss: 0.5335 - accuracy: 0.7068\n",
      "Epoch 45/150\n",
      "62/62 [==============================] - 0s 409us/step - loss: 0.5398 - accuracy: 0.7085\n",
      "Epoch 46/150\n",
      "62/62 [==============================] - 0s 412us/step - loss: 0.5397 - accuracy: 0.7166\n",
      "Epoch 47/150\n",
      "62/62 [==============================] - 0s 400us/step - loss: 0.5324 - accuracy: 0.7166\n",
      "Epoch 48/150\n",
      "62/62 [==============================] - 0s 414us/step - loss: 0.5274 - accuracy: 0.7199\n",
      "Epoch 49/150\n",
      "62/62 [==============================] - 0s 409us/step - loss: 0.5560 - accuracy: 0.7085\n",
      "Epoch 50/150\n",
      "62/62 [==============================] - 0s 456us/step - loss: 0.5333 - accuracy: 0.7085\n",
      "Epoch 51/150\n",
      "62/62 [==============================] - 0s 439us/step - loss: 0.5199 - accuracy: 0.7231\n",
      "Epoch 52/150\n",
      "62/62 [==============================] - 0s 416us/step - loss: 0.5493 - accuracy: 0.7248\n",
      "Epoch 53/150\n",
      "62/62 [==============================] - 0s 423us/step - loss: 0.5458 - accuracy: 0.7199\n",
      "Epoch 54/150\n",
      "62/62 [==============================] - 0s 420us/step - loss: 0.5344 - accuracy: 0.7264\n",
      "Epoch 55/150\n",
      "62/62 [==============================] - 0s 410us/step - loss: 0.5336 - accuracy: 0.7215\n",
      "Epoch 56/150\n",
      "62/62 [==============================] - 0s 408us/step - loss: 0.5315 - accuracy: 0.7150\n",
      "Epoch 57/150\n",
      "62/62 [==============================] - 0s 409us/step - loss: 0.5290 - accuracy: 0.7313\n",
      "Epoch 58/150\n",
      "62/62 [==============================] - 0s 410us/step - loss: 0.5220 - accuracy: 0.7394\n",
      "Epoch 59/150\n",
      "62/62 [==============================] - 0s 418us/step - loss: 0.5315 - accuracy: 0.7329\n",
      "Epoch 60/150\n",
      "62/62 [==============================] - 0s 431us/step - loss: 0.5163 - accuracy: 0.7313\n",
      "Epoch 61/150\n",
      "62/62 [==============================] - 0s 417us/step - loss: 0.5199 - accuracy: 0.7492\n",
      "Epoch 62/150\n",
      "62/62 [==============================] - 0s 416us/step - loss: 0.5182 - accuracy: 0.7410\n",
      "Epoch 63/150\n",
      "62/62 [==============================] - 0s 408us/step - loss: 0.5214 - accuracy: 0.7345\n",
      "Epoch 64/150\n",
      "62/62 [==============================] - 0s 427us/step - loss: 0.5239 - accuracy: 0.7280\n",
      "Epoch 65/150\n",
      "62/62 [==============================] - 0s 429us/step - loss: 0.5205 - accuracy: 0.7378\n",
      "Epoch 66/150\n",
      "62/62 [==============================] - 0s 401us/step - loss: 0.5135 - accuracy: 0.7410\n",
      "Epoch 67/150\n",
      "62/62 [==============================] - 0s 409us/step - loss: 0.5279 - accuracy: 0.7264\n",
      "Epoch 68/150\n",
      "62/62 [==============================] - 0s 411us/step - loss: 0.5199 - accuracy: 0.7248\n",
      "Epoch 69/150\n",
      "62/62 [==============================] - 0s 403us/step - loss: 0.5207 - accuracy: 0.7280\n",
      "Epoch 70/150\n",
      "62/62 [==============================] - 0s 427us/step - loss: 0.5081 - accuracy: 0.7378\n",
      "Epoch 71/150\n",
      "62/62 [==============================] - 0s 434us/step - loss: 0.5256 - accuracy: 0.7264\n",
      "Epoch 72/150\n",
      "62/62 [==============================] - 0s 427us/step - loss: 0.5184 - accuracy: 0.7182\n",
      "Epoch 73/150\n",
      "62/62 [==============================] - 0s 409us/step - loss: 0.5067 - accuracy: 0.7394\n",
      "Epoch 74/150\n",
      "62/62 [==============================] - 0s 404us/step - loss: 0.5114 - accuracy: 0.7378\n",
      "Epoch 75/150\n",
      "62/62 [==============================] - 0s 423us/step - loss: 0.5182 - accuracy: 0.7264\n",
      "Epoch 76/150\n",
      "62/62 [==============================] - 0s 413us/step - loss: 0.5212 - accuracy: 0.7476\n",
      "Epoch 77/150\n",
      "62/62 [==============================] - 0s 413us/step - loss: 0.5097 - accuracy: 0.7492\n",
      "Epoch 78/150\n",
      "62/62 [==============================] - 0s 405us/step - loss: 0.5048 - accuracy: 0.7459\n",
      "Epoch 79/150\n",
      "62/62 [==============================] - 0s 417us/step - loss: 0.5147 - accuracy: 0.7362\n",
      "Epoch 80/150\n",
      "62/62 [==============================] - 0s 408us/step - loss: 0.5050 - accuracy: 0.7606\n",
      "Epoch 81/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 409us/step - loss: 0.5017 - accuracy: 0.7508\n",
      "Epoch 82/150\n",
      "62/62 [==============================] - 0s 416us/step - loss: 0.5187 - accuracy: 0.7362\n",
      "Epoch 83/150\n",
      "62/62 [==============================] - 0s 419us/step - loss: 0.5013 - accuracy: 0.7394\n",
      "Epoch 84/150\n",
      "62/62 [==============================] - 0s 408us/step - loss: 0.5067 - accuracy: 0.7557\n",
      "Epoch 85/150\n",
      "62/62 [==============================] - 0s 404us/step - loss: 0.5020 - accuracy: 0.7573\n",
      "Epoch 86/150\n",
      "62/62 [==============================] - 0s 445us/step - loss: 0.5036 - accuracy: 0.7573\n",
      "Epoch 87/150\n",
      "62/62 [==============================] - 0s 421us/step - loss: 0.5012 - accuracy: 0.7557\n",
      "Epoch 88/150\n",
      "62/62 [==============================] - 0s 431us/step - loss: 0.5113 - accuracy: 0.7459\n",
      "Epoch 89/150\n",
      "62/62 [==============================] - 0s 406us/step - loss: 0.5004 - accuracy: 0.7508\n",
      "Epoch 90/150\n",
      "62/62 [==============================] - 0s 442us/step - loss: 0.5010 - accuracy: 0.7492\n",
      "Epoch 91/150\n",
      "62/62 [==============================] - 0s 417us/step - loss: 0.5069 - accuracy: 0.7557\n",
      "Epoch 92/150\n",
      "62/62 [==============================] - 0s 424us/step - loss: 0.5109 - accuracy: 0.7362\n",
      "Epoch 93/150\n",
      "62/62 [==============================] - 0s 437us/step - loss: 0.5043 - accuracy: 0.7264\n",
      "Epoch 94/150\n",
      "62/62 [==============================] - 0s 436us/step - loss: 0.5075 - accuracy: 0.7459\n",
      "Epoch 95/150\n",
      "62/62 [==============================] - 0s 440us/step - loss: 0.5052 - accuracy: 0.7313\n",
      "Epoch 96/150\n",
      "62/62 [==============================] - 0s 445us/step - loss: 0.5010 - accuracy: 0.7427\n",
      "Epoch 97/150\n",
      "62/62 [==============================] - 0s 430us/step - loss: 0.5124 - accuracy: 0.7476\n",
      "Epoch 98/150\n",
      "62/62 [==============================] - 0s 444us/step - loss: 0.5082 - accuracy: 0.7508\n",
      "Epoch 99/150\n",
      "62/62 [==============================] - 0s 416us/step - loss: 0.4948 - accuracy: 0.7443\n",
      "Epoch 100/150\n",
      "62/62 [==============================] - 0s 409us/step - loss: 0.5140 - accuracy: 0.7378\n",
      "Epoch 101/150\n",
      "62/62 [==============================] - 0s 421us/step - loss: 0.5060 - accuracy: 0.7443\n",
      "Epoch 102/150\n",
      "62/62 [==============================] - 0s 443us/step - loss: 0.4995 - accuracy: 0.7524\n",
      "Epoch 103/150\n",
      "62/62 [==============================] - 0s 433us/step - loss: 0.5102 - accuracy: 0.7492\n",
      "Epoch 104/150\n",
      "62/62 [==============================] - 0s 419us/step - loss: 0.4981 - accuracy: 0.7443\n",
      "Epoch 105/150\n",
      "62/62 [==============================] - 0s 421us/step - loss: 0.5009 - accuracy: 0.7524\n",
      "Epoch 106/150\n",
      "62/62 [==============================] - 0s 413us/step - loss: 0.4913 - accuracy: 0.7638\n",
      "Epoch 107/150\n",
      "62/62 [==============================] - 0s 418us/step - loss: 0.5024 - accuracy: 0.7638\n",
      "Epoch 108/150\n",
      "62/62 [==============================] - 0s 415us/step - loss: 0.4989 - accuracy: 0.7655\n",
      "Epoch 109/150\n",
      "62/62 [==============================] - 0s 429us/step - loss: 0.4930 - accuracy: 0.7573\n",
      "Epoch 110/150\n",
      "62/62 [==============================] - 0s 427us/step - loss: 0.4926 - accuracy: 0.7410\n",
      "Epoch 111/150\n",
      "62/62 [==============================] - 0s 407us/step - loss: 0.4918 - accuracy: 0.7606\n",
      "Epoch 112/150\n",
      "62/62 [==============================] - 0s 417us/step - loss: 0.5053 - accuracy: 0.7492\n",
      "Epoch 113/150\n",
      "62/62 [==============================] - 0s 411us/step - loss: 0.5046 - accuracy: 0.7573\n",
      "Epoch 114/150\n",
      "62/62 [==============================] - 0s 415us/step - loss: 0.4954 - accuracy: 0.7557\n",
      "Epoch 115/150\n",
      "62/62 [==============================] - 0s 422us/step - loss: 0.4863 - accuracy: 0.7704\n",
      "Epoch 116/150\n",
      "62/62 [==============================] - 0s 407us/step - loss: 0.5216 - accuracy: 0.7443\n",
      "Epoch 117/150\n",
      "62/62 [==============================] - 0s 438us/step - loss: 0.4991 - accuracy: 0.7655\n",
      "Epoch 118/150\n",
      "62/62 [==============================] - 0s 411us/step - loss: 0.4974 - accuracy: 0.7606\n",
      "Epoch 119/150\n",
      "62/62 [==============================] - 0s 423us/step - loss: 0.4952 - accuracy: 0.7687\n",
      "Epoch 120/150\n",
      "62/62 [==============================] - 0s 446us/step - loss: 0.4849 - accuracy: 0.7573\n",
      "Epoch 121/150\n",
      "62/62 [==============================] - 0s 413us/step - loss: 0.4867 - accuracy: 0.7736\n",
      "Epoch 122/150\n",
      "62/62 [==============================] - 0s 422us/step - loss: 0.4859 - accuracy: 0.7590\n",
      "Epoch 123/150\n",
      "62/62 [==============================] - 0s 402us/step - loss: 0.4854 - accuracy: 0.7655\n",
      "Epoch 124/150\n",
      "62/62 [==============================] - 0s 415us/step - loss: 0.4819 - accuracy: 0.7638\n",
      "Epoch 125/150\n",
      "62/62 [==============================] - 0s 411us/step - loss: 0.5123 - accuracy: 0.7427\n",
      "Epoch 126/150\n",
      "62/62 [==============================] - 0s 424us/step - loss: 0.4884 - accuracy: 0.7720\n",
      "Epoch 127/150\n",
      "62/62 [==============================] - 0s 409us/step - loss: 0.5167 - accuracy: 0.7508\n",
      "Epoch 128/150\n",
      "62/62 [==============================] - 0s 400us/step - loss: 0.5252 - accuracy: 0.7248\n",
      "Epoch 129/150\n",
      "62/62 [==============================] - 0s 421us/step - loss: 0.4870 - accuracy: 0.7573\n",
      "Epoch 130/150\n",
      "62/62 [==============================] - 0s 413us/step - loss: 0.4941 - accuracy: 0.7557\n",
      "Epoch 131/150\n",
      "62/62 [==============================] - 0s 418us/step - loss: 0.4926 - accuracy: 0.7638\n",
      "Epoch 132/150\n",
      "62/62 [==============================] - 0s 427us/step - loss: 0.4807 - accuracy: 0.7590\n",
      "Epoch 133/150\n",
      "62/62 [==============================] - 0s 421us/step - loss: 0.4954 - accuracy: 0.7524\n",
      "Epoch 134/150\n",
      "62/62 [==============================] - 0s 437us/step - loss: 0.4936 - accuracy: 0.7606\n",
      "Epoch 135/150\n",
      "62/62 [==============================] - 0s 424us/step - loss: 0.4895 - accuracy: 0.7671\n",
      "Epoch 136/150\n",
      "62/62 [==============================] - 0s 422us/step - loss: 0.4927 - accuracy: 0.7410\n",
      "Epoch 137/150\n",
      "62/62 [==============================] - 0s 426us/step - loss: 0.4925 - accuracy: 0.7508\n",
      "Epoch 138/150\n",
      "62/62 [==============================] - 0s 412us/step - loss: 0.4953 - accuracy: 0.7557\n",
      "Epoch 139/150\n",
      "62/62 [==============================] - 0s 409us/step - loss: 0.4981 - accuracy: 0.7671\n",
      "Epoch 140/150\n",
      "62/62 [==============================] - 0s 404us/step - loss: 0.4855 - accuracy: 0.7622\n",
      "Epoch 141/150\n",
      "62/62 [==============================] - 0s 423us/step - loss: 0.4977 - accuracy: 0.7557\n",
      "Epoch 142/150\n",
      "62/62 [==============================] - 0s 418us/step - loss: 0.4776 - accuracy: 0.7638\n",
      "Epoch 143/150\n",
      "62/62 [==============================] - 0s 441us/step - loss: 0.4937 - accuracy: 0.7573\n",
      "Epoch 144/150\n",
      "62/62 [==============================] - 0s 446us/step - loss: 0.4947 - accuracy: 0.7590\n",
      "Epoch 145/150\n",
      "62/62 [==============================] - 0s 410us/step - loss: 0.4839 - accuracy: 0.7622\n",
      "Epoch 146/150\n",
      "62/62 [==============================] - 0s 432us/step - loss: 0.4871 - accuracy: 0.7655\n",
      "Epoch 147/150\n",
      "62/62 [==============================] - 0s 421us/step - loss: 0.4856 - accuracy: 0.7638\n",
      "Epoch 148/150\n",
      "62/62 [==============================] - 0s 428us/step - loss: 0.4828 - accuracy: 0.7655\n",
      "Epoch 149/150\n",
      "62/62 [==============================] - 0s 446us/step - loss: 0.4836 - accuracy: 0.7671\n",
      "Epoch 150/150\n",
      "62/62 [==============================] - 0s 421us/step - loss: 0.4863 - accuracy: 0.7687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6d7e2f5b10>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting model\n",
    "kerasmodel.fit(X_train, y_train, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "82ab8b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 493us/step - loss: 0.4933 - accuracy: 0.7622\n",
      "Train Accuracy: 76.22\n"
     ]
    }
   ],
   "source": [
    "# Train accuracy\n",
    "_, accuracy = kerasmodel.evaluate(X_train, y_train)\n",
    "print('Train Accuracy: %.2f' %(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f09b0bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atamuratove/.local/lib/python3.10/site-packages/tensorflow/python/keras/engine/sequential.py:454: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7467532467532467"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = kerasmodel.predict_classes(X_test)\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc3dd15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3560990d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca524ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec21a32d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
